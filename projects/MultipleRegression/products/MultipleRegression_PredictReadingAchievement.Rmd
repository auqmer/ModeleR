---
title: "Multiple Regression - Predicting Reading Achievement"
output: html_document
---

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(echo = TRUE, comment=NULL)

```

After building an intuitive understanding of simple regression we will now expand our model to include more than one predictor. 
But keep this as simple as possible, I will focus mostly on models with two predictors.

First, let's expand the simple regression equation to accommodate multiple predictors.
Equation 1 below is the simple regression equation for the sample.

$$
Y_i = a + b X_i + e_i \tag{1}
$$
Here $Y_i$ is the value on the outcome variable for the $i$th subject, while $X_i$ is the value of the predictor variable for the same subject.
The estimated parameters $a$ and $b$ are the intercept and slope for $X$, which are common for the whole sample (e.g. we only estimate one intercept and one slope that is constant across all individual).
The $e_i$ is the $i$th subjects residual, or the difference between their model predicted score and their observed score.

To expand this we need to add more predictors and be able to distinguish them.

$$
Y_i = a + b_1 X_{1i} + b_2 X_{2i} + ...+ b_k X_{ki} + e_i \tag{2}
$$
This is done, as in equation 2, by adding numeric subscripts to the slope coefficients, and to the predictors.
Note that equation 2 is generic and can accommodate any number of predictors ($k$). 

## Simulating Reading Achievement Model

In this post I will build on what we covered related to simple regression by introducing multiple regression. 
In this post I will use simulated data to model the use of verbal aptitude and achievement motivation to predict reading achievement.
I will use the descriptive statistics from an example in Pedhazur 1998, chapter 5, Table 5.1 as the population parameters.


```{r, warning=FALSE, message=FALSE}
library(psych)
library(arm)
library(texreg)
```


```{r}
dat51 <- data.frame(
  readAch  = c(2, 4, 4, 1, 5, 4, 7, 9, 7, 8, 5, 2, 8, 6, 10, 9, 3, 6, 7, 10),
  verbalApt = c(1, 2, 1, 1, 3, 4, 5, 5, 7, 6, 4, 3, 6, 6, 8, 9, 2, 6, 4, 4),
  achMot = c(3, 5, 3, 4, 6, 5, 6, 7, 8, 4, 3, 4, 6, 7, 7, 6, 6, 5, 6, 9)
)

```

```{r}
pairs(dat51)
```

```{r}
hist(dat51$readAch, main = "Reading Achievement")
```

```{r}
hist(dat51$verbalApt)
```

```{r}
hist(dat51$achMot)
```


```{r}
describe(dat51, fast = TRUE)
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, eval=FALSE}
library(plotrix)
plot(1:130, 1:130, type = "n", xlab = "",ylab = "", xaxt ="n",
     yaxt= "n", bty = "n") 
draw.circle(25, 35, 10, density = 30, angle = 120)
draw.circle(45, 35, 10, density = 30, angle = 60)
draw.circle(35, 60, 10, density = 30) 
text(35, 90, "Y")
text(12, 38, expression('X'[1]))
text(58, 38, expression('X'[2]))

draw.circle(105, 35, 10, density = 30, angle = 120)
draw.circle(95, 35, 10, density = 30, angle = 60)
draw.circle(100, 60, 10, density = 30) 
text(100, 90, "Y")
text(82, 38, expression('X'[1]))
text(118, 38, expression('X'[2]))
```


### Simple Regression: Using Verbal Aptitude to Predict Reading Achievement

```{r}
mody.1 <- lm(readAch ~ verbalApt, data = dat51)
display(mody.1)
```

### Simple Regression: Using Achievement Motivation to Predict Reading Achievement
```{r}
mody.2 <- lm(readAch ~ achMot, data = dat51)
display(mody.2)
```

### Multiple Regression: Using Verbal Aptitude and Achievement Motivation to Predict Reading Achievement
```{r}
mody.12 <- lm(readAch ~ verbalApt + achMot, data = dat51)
display(mody.12)
```


```{r, results = 'asis'}
htmlreg(list(mody.1, mody.2, mody.12))
```

